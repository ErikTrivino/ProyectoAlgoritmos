Librer√≠as
https://www.semanticscholar.org/
https://scholar.google.com/
https://library.uniquindio.edu.co/databases
https://pubmed.ncbi.nlm.nih.gov/
PubMed üè•

Base de datos de art√≠culos m√©dicos y biol√≥gicos.

Tiene una API oficial (Entrez de Biopython), pero tambi√©n permite scraping con BeautifulSoup.




https://ieeexplore.ieee.org/Xplore/home.jsp //necestia logearse y pagar


Se utilizara python con 
pip install requests beautifulsoup4 selenium scholarly pandas
pip install unidecode


Herramientas para Web Scraping:

Python (Recomendado)
Librer√≠as √∫tiles:

requests + BeautifulSoup (para p√°ginas HTML est√°ticas).

selenium (para p√°ginas din√°micas con JavaScript).

scrapy (para proyectos m√°s grandes y automatizados).

scholarly (para extraer datos de Google Scholar, aunque no es tan confiable como Scopus).

 Ejemplo con Python (Scopus/ScienceDirect) El ejemplo se utiliza google academy




An√°lisis bibliom√©trico:

Usar Bibliometrix (R) o Python (pandas + matplotlib) para:

Conteo de autores, instituciones, a√±os.

Nubes de palabras (wordcloud en Python).

Redes de co-ocurrencia (networkx en Python).


C√≥digo de An√°lisis Bibliom√©trico (usando pandas, matplotlib, networkx y wordcloud)
Qu√© hace este c√≥digo?
Estad√≠sticas b√°sicas:

Muestra el n√∫mero total de publicaciones, a√±os de publicaci√≥n y gr√°fico de distribuci√≥n por a√±o.

Nube de palabras:

Genera una visualizaci√≥n de los t√©rminos m√°s frecuentes en los t√≠tulos de los art√≠culos.

Red de coautor√≠a:

Identifica colaboraciones entre autores y crea un gr√°fico de red (√∫til para ver comunidades de investigaci√≥n).

Exportaci√≥n de resultados:

Guarda un CSV con el conteo de publicaciones por autor.




